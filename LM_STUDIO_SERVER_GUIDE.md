# üöÄ LM Studio Server - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ

## 2 —Å–ø–æ—Å–æ–±–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ LM Studio

---

## üñ•Ô∏è –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ GUI (–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)

### –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:

1. **–û—Ç–∫—Ä–æ–π—Ç–µ LM Studio**

2. **–ù–∞–π–¥–∏—Ç–µ –≤–∫–ª–∞–¥–∫—É —Å–µ—Ä–≤–µ—Ä–∞:**
   - –°–ª–µ–≤–∞ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –Ω–∞–π–¥–∏—Ç–µ –∏–∫–æ–Ω–∫—É ‚ÜîÔ∏è –∏–ª–∏ —Ç–µ–∫—Å—Ç **"Local Server"** / **"Developer"**
   - –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ —ç—Ç—É –≤–∫–ª–∞–¥–∫—É

3. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–µ—Ä–≤–µ—Ä:**
   ```
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Local Inference Server          ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ Model to load:                  ‚îÇ
   ‚îÇ [Select model ‚ñº]                ‚îÇ
   ‚îÇ                                 ‚îÇ
   ‚îÇ Select: qwen/qwen3-30b-a3b-2507 ‚îÇ
   ‚îÇ                                 ‚îÇ
   ‚îÇ Port: [1234]                    ‚îÇ
   ‚îÇ GPU Layers: [Auto/Max]          ‚îÇ
   ‚îÇ                                 ‚îÇ
   ‚îÇ [üü¢ Start Server]               ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ```

4. **–ù–∞–∂–º–∏—Ç–µ "Start Server"**

5. **–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!**
   - –ê–¥—Ä–µ—Å: `http://localhost:1234`
   - –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: –∑–µ–ª–µ–Ω—ã–π –∫—Ä—É–∂–æ–∫ üü¢

---

## ‚ö° –°–ø–æ—Å–æ–± 2: –ß–µ—Ä–µ–∑ CLI (—Ñ–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º –ë–ï–ó GUI)

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä **–±–µ–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è GUI LM Studio** (headless mode):

### –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫:

**–ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç–µ bat-—Ñ–∞–π–ª:**
```bash
start_lmstudio_server.bat
```

### –ò–ª–∏ –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—ã:

```bash
# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
lms load qwen/qwen3-30b-a3b-2507 --gpu max --yes

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä
lms server start --port 1234 --cors
```

---

## üìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–æ–º

### 1. `start_lmstudio_server.bat`
**–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ —á–µ—Ä–µ–∑ CLI**
```bash
# –î–≤–æ–π–Ω–æ–π –∫–ª–∏–∫ –∏–ª–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏:
start_lmstudio_server.bat
```
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç Qwen3-30B –≤ –ø–∞–º—è—Ç—å
- –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É 1234
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU

### 2. `check_lmstudio_status.bat`
**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞**
```bash
check_lmstudio_status.bat
```
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
- –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
- –†–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–µ—Ä–≤–µ—Ä
- –ù–∞ –∫–∞–∫–æ–º –ø–æ—Ä—Ç—É

### 3. `stop_lmstudio_server.bat`
**–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞**
```bash
stop_lmstudio_server.bat
```
–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–µ—Ä–≤–µ—Ä

---

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã —Å–µ—Ä–≤–µ—Ä–∞

### –ú–µ—Ç–æ–¥ 1: –ß–µ—Ä–µ–∑ bat-—Ñ–∞–π–ª
```bash
check_lmstudio_status.bat
```

### –ú–µ—Ç–æ–¥ 2: –ß–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä
–û—Ç–∫—Ä–æ–π—Ç–µ: `http://localhost:1234/v1/models`

–î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å JSON —Å –º–æ–¥–µ–ª—è–º–∏:
```json
{
  "data": [
    {
      "id": "qwen/qwen3-30b-a3b-2507",
      ...
    }
  ]
}
```

### –ú–µ—Ç–æ–¥ 3: –ß–µ—Ä–µ–∑ curl
```bash
curl http://localhost:1234/v1/models
```

### –ú–µ—Ç–æ–¥ 4: –ß–µ—Ä–µ–∑ Python
```python
import requests
response = requests.get("http://localhost:1234/v1/models")
print(response.json())
```

---

## üéØ –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å: –æ—Ç –∑–∞–ø—É—Å–∫–∞ –¥–æ —Ä–∞–±–æ—Ç—ã —Å RAG

### –í–∞—Ä–∏–∞–Ω—Ç A: GUI + RAG

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ LM Studio (GUI)
#    - –û—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
#    - Local Server ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å ‚Üí Start Server

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ RAG –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
python rag_web_interface.py

# 3. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä
#    http://localhost:7860
```

### –í–∞—Ä–∏–∞–Ω—Ç B: CLI + RAG (–±–µ–∑ GUI)

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä —á–µ—Ä–µ–∑ CLI (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ)
start_lmstudio_server.bat

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ RAG –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–≤ –¥—Ä—É–≥–æ–º –æ–∫–Ω–µ)
python rag_web_interface.py

# 3. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä
#    http://localhost:7860
```

---

## üõ†Ô∏è –ö–æ–º–∞–Ω–¥—ã lms CLI

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:

```bash
# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
lms ls

# –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
lms ps

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
lms load qwen/qwen3-30b-a3b-2507 --gpu max

# –í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
lms unload qwen/qwen3-30b-a3b-2507

# –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞
lms server status

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
lms server start --port 1234

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
lms server stop

# –ß–∞—Ç —Å –º–æ–¥–µ–ª—å—é –≤ –∫–æ–Ω—Å–æ–ª–∏
lms chat
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏:

```bash
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
lms load <model> --gpu max

# –ß–∞—Å—Ç–∏—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU (50%)
lms load <model> --gpu 0.5

# –ë–µ–∑ GPU (—Ç–æ–ª—å–∫–æ CPU)
lms load <model> --gpu off

# –° –∞–≤—Ç–æ–≤—ã–≥—Ä—É–∑–∫–æ–π —á–µ—Ä–µ–∑ 300 —Å–µ–∫—É–Ω–¥
lms load <model> --ttl 300

# –ö–∞—Å—Ç–æ–º–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
lms load <model> --context-length 8192
```

---

## üîß Troubleshooting

### ‚ùå –û—à–∏–±–∫–∞: "Server already running"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–µ–∫—É—â–∏–π —Å–µ—Ä–≤–µ—Ä
lms server stop

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π –ø–æ—Ä—Ç
lms server start --port 1235
```

### ‚ùå –û—à–∏–±–∫–∞: "Cannot connect to LM Studio"

**–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:**
1. –ó–∞–ø—É—â–µ–Ω –ª–∏ —Å–µ—Ä–≤–µ—Ä?
   ```bash
   lms server status
   ```

2. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ª–∏ –ø–æ—Ä—Ç?
   ```bash
   curl http://localhost:1234/v1/models
   ```

3. –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞?
   ```bash
   lms ps
   ```

### ‚ùå –û—à–∏–±–∫–∞: "Model not found"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
lms ls

# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
lms load qwen/qwen3-30b-a3b-2507 --yes
```

### ‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞

**–ü—Ä–∏—á–∏–Ω—ã:**
- –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞ GPU
- –î—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—Ç GPU
- –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ VRAM

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º GPU
lms unload qwen/qwen3-30b-a3b-2507
lms load qwen/qwen3-30b-a3b-2507 --gpu max
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU:

**–ß–µ—Ä–µ–∑ nvidia-smi:**
```bash
nvidia-smi
```

**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:**
```bash
nvidia-smi -l 1
```

**–û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è Qwen3-30B:**
- VRAM: ~18-20 GB
- GPU Load: 30-90% (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤)

---

## üöÄ –ê–≤—Ç–æ–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ Windows

### –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞:

1. –û—Ç–∫—Ä–æ–π—Ç–µ **–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞–Ω–∏–π** (Task Scheduler)
2. **–°–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É** ‚Üí **–û–±—â–∏–µ**:
   - –ò–º—è: "LM Studio Server"
   - –í—ã–ø–æ–ª–Ω—è—Ç—å –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Å–∏—Å—Ç–µ–º—É
3. **–¢—Ä–∏–≥–≥–µ—Ä—ã** ‚Üí –î–æ–±–∞–≤–∏—Ç—å:
   - –ü—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Å–∏—Å—Ç–µ–º—É
4. **–î–µ–π—Å—Ç–≤–∏—è** ‚Üí –î–æ–±–∞–≤–∏—Ç—å:
   - –ü—Ä–æ–≥—Ä–∞–º–º–∞: `C:\Users\PC\start_lmstudio_server.bat`
5. **–°–æ—Ö—Ä–∞–Ω–∏—Ç—å**

–¢–µ–ø–µ—Ä—å —Å–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!

---

## üí° –ü–æ–ª–µ–∑–Ω—ã–µ —Å–æ–≤–µ—Ç—ã

### 1. –†–∞–±–æ—Ç–∞ –≤ —Ñ–æ–Ω–µ
–°–µ—Ä–≤–µ—Ä CLI —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ - –º–æ–∂–µ—Ç–µ –∑–∞–∫—Ä—ã—Ç—å –æ–∫–Ω–æ –∫–æ–Ω—Å–æ–ª–∏ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ (–µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω—ã –ª–æ–≥–∏).

### 2. –ù–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
```bash
# –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å
lms load –¥—Ä—É–≥–∞—è-–º–æ–¥–µ–ª—å --identifier model2
```

### 3. –£–¥–∞–ª–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø
–ï—Å–ª–∏ –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø —Å –¥—Ä—É–≥–∏—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–≤ –≤ —Å–µ—Ç–∏:
```bash
lms server start --port 1234 --cors
```
–ó–∞—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `http://<your-ip>:1234`

### 4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# –ü–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
lms server start --verbose

# –ë–µ–∑ –ª–æ–≥–æ–≤
lms server start --quiet
```

---

## üìñ API Documentation

LM Studio –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API:

**Base URL:** `http://localhost:1234/v1`

**Endpoints:**
- `/v1/models` - —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
- `/v1/chat/completions` - —á–∞—Ç
- `/v1/completions` - —Ç–µ–∫—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- `/v1/embeddings` - embeddings (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)

**–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ (curl):**
```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen/qwen3-30b-a3b-2507",
    "messages": [{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}],
    "temperature": 0.7,
    "max_tokens": 100
  }'
```

**–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ (Python):**
```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:1234/v1", api_key="not-needed")

response = client.chat.completions.create(
    model="qwen/qwen3-30b-a3b-2507",
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}],
    temperature=0.7
)

print(response.choices[0].message.content)
```

---

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º RAG

- [ ] LM Studio —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω (GUI –∏–ª–∏ CLI)
- [ ] –ú–æ–¥–µ–ª—å Qwen3-30B –∑–∞–≥—Ä—É–∂–µ–Ω–∞
- [ ] –°–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ `http://localhost:1234/v1/models`
- [ ] –ï—Å—Ç—å —Å–≤–æ–±–æ–¥–Ω–æ ~18GB VRAM –Ω–∞ GPU
- [ ] –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤—Å–µ Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
- [ ] –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ –ø—É—Ç–∏

–ï—Å–ª–∏ –≤—Å–µ ‚úÖ - –∑–∞–ø—É—Å–∫–∞–π—Ç–µ RAG!

---

**–°–æ–∑–¥–∞–Ω–æ:** –û–∫—Ç—è–±—Ä—å 2025
**–î–ª—è:** RTX 3090, LM Studio, Windows
